---
title: Reproducibility and the Philosophy of Data
author: jonthelaion
date: '2018-04-26 7:03:00'
slug: reproducibility-and-the-philosophy-of-data
categories:
  - podcast
  - twimlai
  - datascience
  - reproducibility
tags:
  - podcast
  - twimlai
  - datascience
  - reproducibility
---
**Guest:** Clare Gollnick

**Link:** <a href="https://twimlai.com/twiml-talk-121-reproducibility-philosophy-data-clare-gollnick/" target="_blank">TWIMLAI Talk #121</a>

A very interesting talk about the reproducibility controversy that is rocking the scientific community. A "Nature" survey in 2016 showed that more than 70% of researchers have tried and failed to reproduce another scientist's experiments, and more than half have failed to reproduce their own experiments.

To a certain extent, this could be a result of the reliance on the p-value as the test of statistical significance in scientific studies. This reliance exposes studies to the risk of "p-hacking", where scientists re-run and re-analyse data until a sufficiently low p-value is obtained. 

Interestingly, this iterative process parallels the way that data science is used to generate predictive models. To mitigate this risk, the data science process includes a cross-validation step which tests the model against a data set that was not used in the construction of the model and while this does not completely eliminate the risk, it goes a long way towards minimising it. Overfitting on test sets in data science is the equivalent to p-hacking in scientific studies.

There is a field of study known as the **philosphy of data** which explores why it is that we believe we can learn from data. Because all the data we collect is data about the past, one implicit assumption that we make is that there is a set of shared rules about the past and the future. We are assuming that due to these shared rules, data about the past can be generalised and used to predict the future. If data from the past was purely random, then there would be no point in using it to try to understand or predict the future.

In practice, it is important to think about this core assumption when "framing the problem". Machine learning solutions tend to work better when there is a set of clear rules and it is important to frame the problem in that way if possible. This will involve domain expertise to understand the assumptions/rules when for example, selecting features.

To understand the philosophy of data further:

- David Hume: The problem of induction
- Karl Popper: Falsifiability, you never prove anything is true, just demonstrate that the best idea you have is not yet false
- Infinite monkey thought experiment

When making a strategic investment into a data solution, the general rule is to invest into the solution that describes how the question was approached/reframed rather than the one that simply picked the best model out of the thousands that were run. The former approach usually generates a model that has a higher likelihood of being able to be generalised once put into production.

Decisions in practice are made based on expected outcomes rather than probabilities. While there may be diminishing returns in the last 90%-95% of tuning a model, if the consequences of getting it wrong are catastrophic, then it may be worthwhile investing the time/resources into getting it right. However, as a general rule, the first step should still involve building a model with an understanding of the problem.