---
title: The Data Scientist's Toolbox (Coursera)
author: jonthelaion
date: '2018-04-07'
slug: the-data-scientist-s-toolbox-coursera
categories:
  - datascience
  - R
  - mooc
  - coursera
tags:
  - datascience
  - R
  - mooc
  - coursera
---

# Introduction

- Question should come first; data should come second
- Rarely will you have full, complete and clean data that you need to answer the question
- Statistics is the science of learning from data and is used wherever there is uncertainty
- What do data scientists do?
 - Define the question
 - Define the ideal question set
 - Determine what data you can access
 - Obtain the data
 - Clean the data
 - Exploratory data analysis
 - Statistical prediction/modeling
 - Interpret results
 - Challenge results
 - Synthesize/write up results
 - Create reproducible code
 - Distribute results to other people
- Key characteristics of "hackers"
 - Willing to find answers on their own
 - Knowledgeable about where to find answers on their own
 - Unintimidated by new data types or packages
 - Unafraid to say they don't know the answer
 - In summary: Polite but relentless

# Command Line Interface

- CLI commands follow this recipe: `command` `flags` `arguments`
- `pwd`: prints working directory
- `clear`: clears CLI screen
- `ls`: lists all files in current directory
 - `-a`: lists both hidden and unhidden files
 - `-l`: lists details of unhidden files
 - `al`: lists details of both hidden and unhidden files
- `cd <path>`: change directory to path
 - `cd <blank>`: go to home directory
 - `cd ..`: go up one level
- `mkdir`: make directory in working directory
- `touch <file-name>`: creates an empty file in working directory
- `cp <file-to-copy> <dir-to-copy-to>`: to copy single file
- `cp -r <dir-to-copy> <dir-to-copy-to>`: this copy entire folder
- `rm <file-to-delete>`: to delete single file
- `rm -r <dir-to-delete>`: to delete entire folder (Note: no way to undo this, so use with caution)
- `mv <file-to-move> <dir-to-move-to>`: to move single file
- `mv <file-to-rename> <file-new-name>`: to rename single file
- `echo <text>`: prints text
- `date`: prints current date and time

# Conceptual Ideas

- Types of data science questions in approximate order of difficulty:
 - **Descriptive:** Describe data and interpret what it means. Descriptions usually cannot be generalised without additional statistical modeling. Example: Census data, Google Ngram Viewer
 - **Exploratory:** Find relationships you didn't know about. Good for discovering new connections and defining future studies. Exploratory analyses are usually not the final say and should not be used for generalising/predicting alone. Correlation does not imply causation.
 - **Inferential:** Use a relativly small sample of data to say something about a larger population. Common goal of statistical analysis and involves estimating both the quantity you care about and the uncertainty about your estimate. Inference depends heavily on both the population and the sampling scheme. Example: Study showing the effect of air pollution control on life expectancy
 - **Predictive:** Use data on some objects to predict values on other objects. If X predicts Y, it does not mean that X causes Y. Accurate prediction depends heavily on measuring the right variables. Although there are better and worse prediction models, more data and a simple model works really well. Prediction is very hard, especially about the future references. Example: Prediction of presedential elections
 - **Causal:** To find out what happens to one variable when you make another variable change. Usually randomised studies are required to identify causation. There are approaches to inferring causation in non-randomised studies, but they are complicated and sensitive to assumptions. Causal relationships are usually identified as average effect, but may not apply to every individual. Causal models are usually the gold standard for data analysis.
 - **Mechanistic:** To understand the exact changes in variables that lead to changes in other varaibles for individual objects. Incredibly hard to infer, except in simple situations. Usually modelled by a deterministic set of equations (physical/engineering science). Generally the random component of the data is measurement error If the equations are known but the parameters are not, they may be inferred with data analysis.
- What is data?
 - "Data are values of qualitative or quantitative variables, belonging to a set of items."
 - Data can come in a variety of formats e.g. Excel table format, genome sequencing data, Twitter API, medical data, videos files, images.
 - Data is the second most important thing - the most important is the question.
 - Often the data will limit or enable the questions, but having data can't save you if you don't have a question.
 - "The data may not contain the answer. The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data." -John Tukey.

# Experimental Design

- Know and care about the analysis design
- Have a plan for data and code sharing
- Formulate your question in advance
- Statistical inference - inference from sample to population
- Consider variability - ideally want small variability on existing and new results
- Confounding variables - paying attention to what other variable may be causing the relationship (e.g. age is a confounding variable for "relationship" observed between shoe size and literacy)
- Randomisation and blocking:
 - If you can (and want to) fix a variable
 - If you don't fix a variable, stratify it
 - If you can't fix or stratify varaible, randomise it
- Prediction versus inference
 - For prediction, the distributions should be relatively separated
- Prediction key quantities
 - Sensitivity: Pr(positive test | disease)
 - Sepecificity: Pr(negative test | no disease)
 - Positive predictive value: Pr(disease | positive test)
 - Negative predictive value: Pr(no disease | negative test)
 - Accuracy: Pr(correct outcome)
- Good experiments:
 - Have replication
 - Measure variability
 - Generalise to the problem you care about
 - Are transparent
- Prediction is not inference
 - Both can be important
- Beware data dredging
 