<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Datascience on jonthelaion</title>
    <link>/tags/datascience/</link>
    <description>Recent content in Datascience on jonthelaion</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 28 Apr 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/datascience/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Machine Learning Toolbox (DataCamp)</title>
      <link>/post/machine-learning-toolbox-datacamp/</link>
      <pubDate>Sat, 28 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/machine-learning-toolbox-datacamp/</guid>
      <description>Supervised Learning  The caret package in R automates supervised learning (a.k.a. predictive modelling) where the target variable is available. There are two types of predictive models:  Classification: Qualitative target variable Regression: Quantitative target variable  An important step for both classification and regression models is to use quantifiable and objectic metrics to evaluate the accuracy of the model.  Regression  Root Mean Squared Error (RMSE) is a common metric used for regression (e.</description>
    </item>
    
    <item>
      <title>The Art of Data Science (Book)</title>
      <link>/post/the-art-of-data-science-book/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/the-art-of-data-science-book/</guid>
      <description>Data Analysis as Art  Data analysts have many tools at their disposal, from linear regression to classification trees and even deep learning, but ultimately, a data analyst must find a way to assemble all the tools available and apply them to data to answer a relevant question - a question of interest to people.  Epicycles of Analysis  Data analysis is a highly iterative and non-linear process, better reflected as a series of epicycles, in which information is learned at each step, which then informs whether (and how) to refine, and redo, the step that was just performed, or whether (and how) to proceed to the next step.</description>
    </item>
    
    <item>
      <title>Reproducibility and the Philosophy of Data</title>
      <link>/post/reproducibility-and-the-philosophy-of-data/</link>
      <pubDate>Thu, 26 Apr 2018 07:03:00 +0000</pubDate>
      
      <guid>/post/reproducibility-and-the-philosophy-of-data/</guid>
      <description>Guest: Clare Gollnick
Link: TWIMLAI Talk #121
A very interesting talk about the reproducibility controversy that is rocking the scientific community. A &amp;ldquo;Nature&amp;rdquo; survey in 2016 showed that more than 70% of researchers have tried and failed to reproduce another scientist&amp;rsquo;s experiments, and more than half have failed to reproduce their own experiments.
To a certain extent, this could be a result of the reliance on the p-value as the test of statistical significance in scientific studies.</description>
    </item>
    
    <item>
      <title>Getting and Cleaning Data</title>
      <link>/post/getting-and-cleaning-data/</link>
      <pubDate>Sat, 07 Apr 2018 20:00:00 +0000</pubDate>
      
      <guid>/post/getting-and-cleaning-data/</guid>
      <description>Raw versus Processed Data  Raw data  The original source of the data Often hard to use for data analysis Data analysis includes processing Raw data may only need to be processed once  Processed data  Data that is ready for analysis Processing can include merging, subsetting, transforming, etc. There may be standards for processing All steps should be recorded.   The components of tidy data  The four things you should have:  The raw data The tidy data set A code book describing each variable and its values in the tidy data set (a.</description>
    </item>
    
    <item>
      <title>The Data Scientist&#39;s Toolbox (Coursera)</title>
      <link>/post/the-data-scientist-s-toolbox-coursera/</link>
      <pubDate>Sat, 07 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/the-data-scientist-s-toolbox-coursera/</guid>
      <description>Introduction  Question should come first; data should come second Rarely will you have full, complete and clean data that you need to answer the question Statistics is the science of learning from data and is used wherever there is uncertainty What do data scientists do?  Define the question Define the ideal question set Determine what data you can access Obtain the data Clean the data Exploratory data analysis Statistical prediction/modeling Interpret results Challenge results Synthesize/write up results Create reproducible code Distribute results to other people  Key characteristics of &amp;ldquo;hackers&amp;rdquo;  Willing to find answers on their own Knowledgeable about where to find answers on their own Unintimidated by new data types or packages Unafraid to say they don&amp;rsquo;t know the answer In summary: Polite but relentless   Command Line Interface  CLI commands follow this recipe: command flags arguments pwd: prints working directory clear: clears CLI screen ls: lists all files in current directory  -a: lists both hidden and unhidden files -l: lists details of unhidden files al: lists details of both hidden and unhidden files  cd &amp;lt;path&amp;gt;: change directory to path  cd &amp;lt;blank&amp;gt;: go to home directory cd .</description>
    </item>
    
    <item>
      <title>Data Quality</title>
      <link>/post/data-quality/</link>
      <pubDate>Thu, 05 Apr 2018 21:15:00 +0000</pubDate>
      
      <guid>/post/data-quality/</guid>
      <description>HBR - If your data is bad your machine learning tools are useless  Link: https://hbr.org/2018/04/if-your-data-is-bad-your-machine-learning-tools-are-useless &amp;ldquo;Garbage-in garbage-out&amp;rdquo; adage is equally applicable to machine learning. The quality demands of machine learning are steep - both at the training stage and when using the model in production. To properly train a predictive model, historical data must meet exceptionally broad and high quality standards:  The data must be correct, properly labelled, deduped etc.</description>
    </item>
    
    <item>
      <title>Data Framed</title>
      <link>/post/data-framed/</link>
      <pubDate>Wed, 04 Apr 2018 06:40:00 +0000</pubDate>
      
      <guid>/post/data-framed/</guid>
      <description>Data Framed is a great podcast at DataCamp hosted by Hugo Bowne-Anderson and can be found here. Each week, he invites working data scientists from various backgrounds onto his podcast to talk about their own experiences; how they got to where they are; and all other things data. For me, it&amp;rsquo;s inspiring to hear about all the great work that is being done in the industry and also comforting to know that others have often taken a meandering path by following their interests to get to where they are.</description>
    </item>
    
    <item>
      <title>Doing Data Science (Book)</title>
      <link>/post/doing-data-science-book/</link>
      <pubDate>Sun, 01 Apr 2018 17:30:00 +0000</pubDate>
      
      <guid>/post/doing-data-science-book/</guid>
      <description>With years of experience in both academia and industry, authors Cathy O&amp;rsquo;Neil &amp;amp; Rachel Schutt look beyond the hype to explore what the data science discipline entails and looks like in practice.
They also explore an idea that is often overlooked when speaking about data science - that building models and working with data is not value-neutral. You choose the problems you will work on, you make assumptions in those models, you choose metrics, and you design the algorithms.</description>
    </item>
    
  </channel>
</rss>